vllm-cuda:
    # Clone vllm
	pip install -U ninja packaging --no-cache-dir
	git clone https://github.com/vllm-project/vllm.git vllm

build-vllm-cuda: vllm-cuda
	cd vllm && git fetch && git checkout 997df46a32f3b2c2debe3e17730895cef0d94d2a
	cd vllm && python setup.py build

install-vllm-cuda: build-vllm-cuda
	pip uninstall vllm -y || true
	cd vllm && python setup.py install

vllm-rocm:
    # Clone vllm
	pip install -U ninja packaging --no-cache-dir
	git clone https://github.com/fxmarty/rocm-vllm.git vllm

build-vllm-rocm: vllm-rocm
	cd vllm && git fetch && git checkout ca6913b3c2ffacdcb7d15e914dc34adbc6c89479
	cd vllm && PYTORCH_ROCM_ARCH="gfx90a;gfx942" python setup.py install

install-vllm-rocm: build-vllm-rocm
	pip uninstall vllm -y || true
	cd vllm && python setup.py install
