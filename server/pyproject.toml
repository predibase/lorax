[tool.poetry]
name = "lorax-server"
version = "0.1.0"
description = "LoRAX Inference Python gRPC Server"
authors = ["Geoffrey Angus <geoffrey@predibase.com>", "Travis Addair <travis@predibase.com>","Olivier Dehaene <olivier@huggingface.co>"]

[tool.poetry.scripts]
lorax-server = 'lorax_server.cli:app'

[tool.poetry.dependencies]
python = "^3.9"
protobuf = "^4.21.7"
grpcio = "^1.51.1"
grpcio-status = "^1.51.1"
grpcio-reflection = "^1.51.1"
grpc-interceptor = "^0.15.0"
typer = "^0.6.1"
accelerate = { version = "^0.24.1", optional = true }
bitsandbytes = { version = "^0.41.1", optional = true }
scipy = { version = "^1.0.0", optional = true }
safetensors = "0.3.1"
loguru = "^0.6.0"
opentelemetry-api = "^1.15.0"
opentelemetry-exporter-otlp = "^1.15.0"
opentelemetry-instrumentation-grpc = "^0.42b0"
hf-transfer = "^0.1.2"
sentencepiece = "^0.1.97"
tokenizers = "0.15.0"
huggingface-hub = "^0.19.4"
transformers = "^4.36.1"
einops = "^0.6.1"
tiktoken = "^0.5.2"
texttable = { version = "^1.6.7", optional = true }
datasets = { version = "^2.14.0", optional = true }
torch = {version = "2.1.1", optional = true }
peft = {version = "0.4.0", optional = true }
boto3 = "^1.28.34"
urllib3 = "<=1.26.18"
stanford-stk = "^0.0.6"
hqq = "^0.1.1"

[tool.poetry.extras]
torch = ["torch"]
accelerate = ["accelerate"]
bnb = ["bitsandbytes"]
peft = ["peft"]
quantize = ["texttable", "datasets", "accelerate"]

[tool.poetry.group.dev.dependencies]
grpcio-tools = "^1.51.1"
pytest = "^7.3.0"


[[tool.poetry.source]]
name = "pytorch-gpu"
url = "https://download.pytorch.org/whl/cu118"
priority = "explicit"

[tool.pytest.ini_options]
markers = ["private: marks tests as requiring an admin hf token (deselect with '-m \"not private\"')"]

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"
